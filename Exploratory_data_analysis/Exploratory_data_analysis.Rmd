---
title: "Exploratory Data Analysis with R"
author: "Kateřina Večerková vecerkok@vscht.cz"
date: "8/15/2024"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
---

# Introduction to Exploratory Data Analysis (EDA)
## What is EDA?

Exploratory Data Analysis (EDA) is the first and crucial step when working with any dataset. It allows us to familiarize ourselves with the data by summarizing its main characteristics, using graphs and visualizations, and forming informed hypotheses. EDA helps in driving the selection of features for modeling by understanding the data and uncovering patterns, trends, missing values, anomalies, or relationships that guide further analysis.

## Key Steps in EDA

- **Understanding Variable Types:** Identify and understand the different types of variables in your dataset.
- **Univariate Analysis:** Summarize and visualize each variable individually to understand its distribution and basic statistics using histograms, box plots, and measures of central tendency.
- **Bivariate Analysis:** Explore the relationship between two variables at a time with scatter plots, correlation analyses, and similar techniques.
- **Multivariate Analysis:** Investigate relationships among more than two variables using techniques such as correlation matrices, pair plots, and dimensionality reduction methods like Principal Component Analysis (PCA).
- **Data Cleaning and Transformation:** Address missing values, transform variables, engineer new features, and select relevant features for further analysis.

## Introducing the Titanic Dataset

For this tutorial, we will use the Titanic dataset, a classic dataset in data science and machine learning. The Titanic dataset provides information about the passengers who were aboard the RMS Titanic, which tragically sank on its maiden voyage in 1912. 

This dataset is rich in both categorical and numerical variables, making it ideal for practicing Exploratory Data Analysis (EDA). It includes information such as:

- **PassengerId:** A unique identifier for each passenger.
- **Survived:** Whether the passenger survived (1) or did not survive (0).
- **Pclass:** The passenger's class (1st, 2nd, or 3rd).
- **Name:** The name of the passenger.
- **Sex:** The gender of the passenger.
- **Age:** The age of the passenger.
- **SibSp:** The number of siblings or spouses the passenger had aboard the Titanic.
- **Parch:** The number of parents or children the passenger had aboard the Titanic.
- **Ticket:** The ticket number.
- **Fare:** The amount of money the passenger paid for the ticket.
- **Cabin:** The cabin number (if available).
- **Embarked:** The port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).

The Titanic dataset is widely used for tutorials because it offers a variety of data types and challenges, such as missing values, categorical data, and potential interactions between variables. It’s a great way to practice EDA techniques and gain insights that can guide more advanced analyses or predictive modeling.

Throughout this tutorial, we will perform an Exploratory Data Analysis on the Titanic dataset to understand the characteristics of the passengers, explore survival rates, and identify key factors that might have influenced survival.

# Loading and Understanding Your Data

```{r, warning=FALSE, message=FALSE}
install.packages("tidyverse")
install.packages("plyr")
install.packages("patchwork")
install.packages("reshape2")
install.packages("GGally")
install.packages("factoextra")
library(patchwork)
library(plyr)
library(tidyverse)
library(dplyr)
library(tidyr)
library(reshape2)
library(GGally)
library(factoextra)
```

## Importing Data into R

```{r}
library(readr)
titanic_data <- read_csv("titanic.csv")
head(titanic_data)
```

## Understanding the Structure of the Data

The `str()` function provides a concise summary of the dataset, showing the number of observations (rows), the number of variables (columns) and the data type for ieach variable (e.g. integer, factor, character).

```{r}
str(titanic_data)
```

## Summary Statistics

To get a quick summary of each variable including basic descriptive statistics for numerical variables and frequency counts for categorical variables, use the `summary()` function.

```{r}
summary(titanic_data)
```

## Identifying Missing Values

```{r}
colSums(is.na(titanic_data))
```

Here we can see that the columns `Age`, `Cabin`, `Embarked` contain missing values, we will need to pay attention to this during data cleaning.

# Data Cleaning and Preparation

Before diving deeper into analysis, it’s crucial to ensure that your data is clean, consistent, and ready for exploration. Data cleaning and preparation is a foundational step in any data analysis project, where we address issues like missing values, inconsistencies, and incorrect data types. This process not only improves the quality of your analysis but also helps in drawing more accurate and reliable conclusions.

In this chapter, we will walk through the essential techniques and best practices for cleaning and preparing your dataset. By the end of this section, you'll be equipped to handle common data challenges and transform raw data into a structured format that’s ready for analysis.

## Handling Missing Values

Common approaches to dealing with missing data:

- remove rows with missing values entirely
- imputing missing data with
  - mean/median/mode
  - neighboring values
  - predicted values
- leaving missing data as is (tree-based methods)

What do you think are their pros & cons?

### Missing values in the `Age` column

```{r}
# let's first examine the distribution of values in the Age column
library(ggplot2)
ggplot(titanic_data, aes(x=Age)) + geom_histogram(bins = 30)
```

Notice the warning caused by the 177 missing values.

```{r}
qqnorm(titanic_data$Age)
qqline(titanic_data$Age, col="steelblue", lwd = 2)
```

We see that the distribution of `Age` is skewed to the left (positive skew). We will use the most common value to fill in the missing ones. Which is why we will use

- the mean,
- the mode or
- the median?

```{r}
# create frequency table and get mode
frequency_table <- table(titanic_data$Age)
mode_value <- as.numeric(names(frequency_table)[which.max(frequency_table)])
mode_value
```

Unfortunately there is no implemented function for `mode` in R, so we will create a frequency table for all the values in the `Age` column and pick the most frequent one, which in this case is 24.

```{r}
# replace missing values in the Age column with the mode
titanic_data <- titanic_data %>% mutate(Age = replace_na(Age, mode_value))
sum(is.na(titanic_data$Age))
```

```{r}
ggplot(titanic_data, aes(x=Age)) + geom_histogram(bins = 30)
```

From the histogram after imputation we can see that we modified the distribution significantly. It is a compromise that we need to take because in this case our best guess is the mode.

### Missing values in the Cabin column

687 out of 891 of the values in the Cabin column are missing which tells us that this column is not very informative or the survival probability. For this specific case, we will remove the column from the dataset entirely.

```{r}
# drop the Cabin column
titanic_data <- titanic_data %>% select(-Cabin)
head(titanic_data)
```

### Missing values in the Embarked column

The Embarked column is a categorical one with three possible values: S, C or Q. The most frequent one is S (644 occurrences out of 889). We will replace the missing values with the most frequent one.

```{r}
ggplot(titanic_data, aes(x = Embarked)) + geom_bar()
```

```{r}
# replace the missing values in the Embarked column
count_table <- titanic_data %>% plyr::count("Embarked")
most_frequent <- count_table %>% filter(freq == max(freq)) %>% pull("Embarked")
titanic_data <- titanic_data %>% mutate(Embarked = replace_na(Embarked, most_frequent))
sum(is.na(titanic_data$Embarked))
```

```{r}
ggplot(titanic_data, aes(x = Embarked)) + geom_bar()
```
Finally let's convert the column type to categorical.

```{r}
titanic_data$Embarked <- as.factor(titanic_data$Embarked)
```

## Data Transformation

Data transformation is a crucial step in data preparation and analysis. It involves modifying, reshaping, or aggregating your data to make it more suitable for analysis. This process allows you to derive new insights, prepare data for modeling, and ensure that the dataset is in the right format for visualization or further processing.

### Column names

```{r}
# check if columns are named consistently
colnames(titanic_data)
# some of the column names are not self-explanatory, some are also shortened, let's unify them
titanic_data <- titanic_data %>% rename(passenger_id = PassengerId, survived = Survived, passenger_class = Pclass, name = Name, sex = Sex, age = Age, siblings_spouses = SibSp, parents_children = Parch, ticket = Ticket, fare = Fare, embarked = Embarked)
colnames(titanic_data)
```

### Changing column data types

```{r}
# the intention here is to minimize the number of unique values in each column to reduce dimensionality
lapply(titanic_data %>% select(-passenger_id, -name, -ticket), unique) # exclude columns that obviously have a unique value in each row
```

```{r}
# even though the data type of the age column is float, most values in the age column are an integer, let's convert the values to the closest integer
titanic_data <- titanic_data %>% mutate(age = round(age))
```

```{r}
unique(titanic_data$age)
```

We reduced the number of unique values in the `age` column from 88 to 71. Another float column with a lot of unique values if the `fare` column. Let's try to see if the correlation with the `survived` column changes if we round these values.

```{r}
# titanic_data <- titanic_data %>% mutate(fare_rounded = round(fare))
# cor(titanic_data$fare, titanic_data$survived)
# cor(titanic_data$fare_rounded, titanic_data$survived)
```

```{r}
# titanic_data <- titanic_data %>% select(-fare) %>% rename(fare = fare_rounded)
# length(unique(titanic_data$fare))
```

The correlation coefficient doesn't get affected much and we reduced the number of unique values from 248 to 90!

The next step is to convert the `sex` column to categorical.

```{r}
titanic_data$sex <- as.factor(titanic_data$sex)
```

### Creating new columns

Here we will focus on creating new columns. Is there a column that combines more pieces information that could be split into more columns? Let's look at the `name` column. What can we extract from it?

#### Extracting title from `name`

```{r}
head(titanic_data$name)
```

It seems that the `name` column follows the format: last_name, title first_name(s) "nickname" (more_first_names?).

```{r}
# first we split the last name from the title and the last name separated by ","
titanic_data <- titanic_data %>% mutate(title_and_first_names = (str_split(name, ", ", simplify = TRUE))[,2])
titanic_data <- titanic_data %>% mutate(title = str_split(title_and_first_names, " ", simplify = TRUE)[, 1])
titanic_data <- titanic_data %>% select(-title_and_first_names)
head(titanic_data$title)
```

```{r}
ggplot(titanic_data, aes(x = title)) + geom_bar()
```

Now that we successfuly extracted the title, let's look at the values. We see that there are some dominant titles like Mr., Mrs., Miss., Master and maybe even Dr. and Rev. The remaining titles are rare. To reduce the number of unique values let's classify these rare titles into Other.

```{r}
titanic_data <- titanic_data %>% mutate(
    title = if_else(title %in% c("Mr.", "Mrs.", "Miss.", "Master.", "Dr.", "Rev."), 
                    title, 
                    "Other")
  )
```

```{r}
ggplot(titanic_data, aes(x = title)) + geom_bar()
```

```{r}
# finally let's convert the title column to categorical
titanic_data$title <- as.factor(titanic_data$title)
```

```{r}
str(titanic_data)
```

## Dealing with Outliers

```{r}
# let's identify outliers of the numerical columns

p1 <- ggplot(titanic_data, aes(x = age)) + geom_boxplot() + coord_flip()
p2 <- ggplot(titanic_data, aes(x = siblings_spouses)) + geom_boxplot() + coord_flip()
p3 <- ggplot(titanic_data, aes(x = parents_children)) + geom_boxplot() + coord_flip()
p4 <- ggplot(titanic_data, aes(x = fare)) + geom_boxplot() + coord_flip()

combined_plot <- p1 + p2 + p3 + p4 + plot_layout(ncol = 4)

combined_plot
```
Discussion: how would you treat these outliers?

## Normalizing/Standardizing Data

### Introduction to Normalization and Standardization

- **Normalization**: Scaling features to a fixed range, typically [0, 1]. Useful when you need features to be on a similar scale, especially for algorithms that are sensitive to the magnitude of features, like neural networks. Many algorithms perform better when features are on a similar scale. Features with larger scaled can dominate distance metrics and gradient-based methods.
- **Standardization**: Transforming features to have a mean of 0 and a standard deviation of 1. Useful when data needs to have the properties of a standard normal distribution, which is important for algorithms that assume normally distributed data, like linear regression.

### Some Exaplmes of Methods for Normalizing/Standardizing Data

- **Min-Max Normalization** `(x - min(x)) / (max(x) - min(x))`
- **Z-Score Standardization** `(x - mean(x)) / sd(x)`
- **Robust Scaling** `(x - median(x)) / IQR(x)`

We have 4 numerical columns: `siblings_spouses`, `parents_children`, `age` and `fare`. When it comes to the first two, even though they are quantitative, they have specific interpretations in their raw form so we won't normalize/standardize them. The `age` and `fare` column however we'll normalize.

```{r}
# min-max normalization of the age column
normalize <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

titanic_data <- titanic_data %>%
  mutate(
    age = normalize(age)
  )

ggplot(titanic_data, aes(x = age)) + geom_histogram(bins = 30)
```

```{r}
# robust scaling of the fare column
robust_scale <- function(x) {
  (x - median(x, na.rm = TRUE)) / IQR(x, na.rm = TRUE)
}

titanic_data <- titanic_data %>%
  mutate(
    fare = robust_scale(fare)
  )

ggplot(titanic_data, aes(x = fare)) + geom_histogram(bins = 30)
```


# Bivariate Analysis

## Correlation Analysis

```{r}
correlation_matrix <- round(cor(titanic_data %>% select(survived, passenger_class, age, siblings_spouses, parents_children, fare)), 2) # considering only numerical columns
melted_correlation_matrix <- melt(correlation_matrix)
ggplot(data = melted_correlation_matrix, aes(x = Var1, y = Var2, fill = value)) + geom_tile()
```

## Scatter Plots

```{r}
p1 <- ggplot(titanic_data, aes(x = passenger_class, y = survived)) +
  geom_point(alpha = 0.5) +
  labs(title = "Passenger class vs Survived")

p2 <- ggplot(titanic_data, aes(x = age, y = survived)) +
  geom_point(alpha = 0.5) +
  labs(title = "Age vs Survived")

p3 <- ggplot(titanic_data, aes(x = siblings_spouses, y = survived)) +
  geom_point(alpha = 0.5) +
  labs(title = "Number of siblings and spouses vs Survived")

p4 <- ggplot(titanic_data, aes(x = parents_children, y = survived)) +
  geom_point(alpha = 0.5) +
  labs(title = "Number of parents and children vs Survived")

p5 <- ggplot(titanic_data, aes(x = fare, y = survived)) +
  geom_point(alpha = 0.5) +
  labs(title = "Fare vs Survived")

# combine individual plots with patchwork
(p1 | p2 | p3) / (p4 | p5)
```

## Pair Plots

```{r}
# select relevant columns
numeric_columns <- titanic_data %>% dplyr::select(age, fare, siblings_spouses, parents_children, survived)

# create a pair plot
ggpairs(numeric_columns) +
  labs(title = "Pair Plot of Selected Titanic Dataset Variables")
```

# Multivariate Analysis

Multivariate analysis enables you to uncover more complex patterns in your data by exploring relationships between multiple variables simultaneously.

## Principal Component Analysis

```{r}
# select numeric columns for PCA
numeric_columns <- titanic_data %>%
  dplyr::select(age, fare, siblings_spouses, parents_children, survived) %>%
  na.omit()  # remove rows with missing values

# perform PCA
pca_result <- prcomp(numeric_columns, scale. = TRUE)
pca_scores <- as.data.frame(pca_result$x)

# add the survived column to the pca scores
pca_scores$survived <- numeric_columns$survived
```

```{r}
ggplot(pca_scores, aes(x = PC1, y = PC2)) +
  geom_point(alpha = 0.7, aes(color = survived)) +
  labs(title = "PC1 vs PC2", x = "PC1", y = "PC2") +
  theme_minimal()
```

```{r}
ggplot(pca_scores, aes(x = PC2, y = PC3)) +
  geom_point(alpha = 0.7, aes(color = survived)) +
  labs(title = "PC2 vs PC3", x = "PC2", y = "PC3") +
  theme_minimal()
```

```{r}
ggplot(pca_scores, aes(x = PC1, y = PC3)) +
  geom_point(alpha = 0.7, aes(color = survived)) +
  labs(title = "PC1 vs PC3", x = "PC1", y = "PC3") +
  theme_minimal()
```

## Clustering Analysis

```{r}
# standardize or normalize the numerical features to ensure they are on a similar scale
scaled_data <- scale(numeric_columns)
```

### K-means clustering

```{r}
# use methods like Elbow Method or Silhouette Analysis to decide the optimal number of clusters
fviz_nbclust(scaled_data, kmeans, method = "wss")
```

```{r}
set.seed(123)  # for reproducibility

# perform k-means clustering
kmeans_result <- kmeans(scaled_data, centers = 3, nstart = 25)

# add cluster assignments to the original data
titanic_data$cluster <- kmeans_result$cluster

# visualize clusters
ggplot(titanic_data, aes(x = age, y = fare, color = as.factor(cluster))) +
  geom_point(alpha = 0.6) +
  labs(title = "K-means Clustering", color = "Cluster") +
  theme_minimal()
```

### Hierarchical clustering

```{r}
# compute distance matrix
dist_matrix <- dist(scaled_data)

# perform hierarchnical clustering
hclust_result <- hclust(dist_matrix, method = "ward.D2")

# cut tree to get clusters
clusters_hc <- cutree(hclust_result, k = 3)

# add cluster assignments to the original data
titanic_data$cluster_hc <- clusters_hc

# plot dendrogram
plot(hclust_result, main = "Hierarchical Clustering Dendrogram") # TODO fix
```

```{r}
ggplot(titanic_data, aes(x = age, y = fare, color = as.factor(cluster_hc))) +
  geom_point(alpha = 0.6) +
  labs(title = "Hierarchical Clustering", color = "Cluster") +
  theme_minimal()
```

# Dealing with High-Dimensional Data
## Dimensionality Reduction
## Feature Selection
# Reporting and Communicating Results
