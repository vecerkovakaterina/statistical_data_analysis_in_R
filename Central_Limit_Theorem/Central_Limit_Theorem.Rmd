---
title: "Central Limit Theorem"
author: "Kateřina Večerková vecerkok@vscht.cz"
date: "2024-09-26"
output: html_document
---

# Central Limit Theorem

## 1. Introduction to the Central Limit Theorem

In this tutorial, we will introduce the concept of the Central Limit Theorem (CLT), why is it important, and how it forms the foundation of many statistical techniques, including hypothesis testing and constructing confidence intervals.

### What is the Central Limit Theorem (CLT)?

The Central Limit Theorem states that the distribution of the sample mean of a sufficientry large sample, drawn from any population, **approaches a normal distribution**.

**In simpler terms:** When we take the mean of different random samples from a population, those sample means will tend to follow a normal distribution as the sample size increases, no matter how the original data is distributed.

### Key Components of the CLT

1. **Independence**: The samples must be drawn independently from the population. This means that the selection of one sample does not influence the selection of another sample.
2. **Sample Size**: While the theorem holds true for any sample size, a larger sample size (typically n ≥ 30) will yield a distribution of sample means that more closely resembles a normal distribution.
3. **Finite Mean and Variance**: The population from which the samples are drawn must have a finite mean and finite variance.

### Demonstrating the CLT

```{r}
# set seed for reproducibility
set.seed(123)

# generate data from different population distributions
normal_dist <- rnorm(1000, mean = 50, sd = 10)   # normal distribution
exponential_dist <- rexp(1000, rate = 0.1)       # exponential distribution
uniform_dist <- runif(1000, min = 20, max = 80)  # uniform distribution

# function to take samples and calculate sample means
sample_means <- function(data, sample_size, num_samples) {
  means <- replicate(num_samples, mean(sample(data, size = sample_size, replace = TRUE)))
  return(means)
}

# set parameters for sampling
sample_size <- 30      # sample size
num_samples <- 1000    # number of samples

# calculate sample means for each distribution
normal_means <- sample_means(normal_dist, sample_size, num_samples)
exponential_means <- sample_means(exponential_dist, sample_size, num_samples)
uniform_means <- sample_means(uniform_dist, sample_size, num_samples)

# plotting histograms to visualize the distributions and sample means
par(mfrow = c(2, 3))  # set up a plotting grid of two rows and three columns

# plot normal distribution
hist(normal_dist, main = "Normal Distribution", 
     xlab = "Value", col = "skyblue", border = "white", freq = FALSE)
lines(density(normal_dist), col = "blue", lwd = 2)

# plot exponential distribution
hist(exponential_dist, main = "Exponential Distribution", 
     xlab = "Value", col = "lightgreen", border = "white", freq = FALSE)
lines(density(exponential_dist), col = "green", lwd = 2)

# plot uniform distribution
hist(uniform_dist, main = "Uniform Distribution", 
     xlab = "Value", col = "orange", border = "white", freq = FALSE)
lines(density(uniform_dist), col = "red", lwd = 2)

# plot sample means for normal distribution
hist(normal_means, main = "Sample Means", 
     xlab = "Sample Mean", col = "lightblue", border = "white", freq = FALSE)
lines(density(normal_means), col = "blue", lwd = 2)

# plot sample means for exponential distribution
hist(exponential_means, main = "Sample Means", 
     xlab = "Sample Mean", col = "lightgreen", border = "white", freq = FALSE)
lines(density(exponential_means), col = "green", lwd = 2)

# plot sample means for uniform distribution
hist(uniform_means, main = "Sample Means", 
     xlab = "Sample Mean", col = "orange", border = "white", freq = FALSE)
lines(density(uniform_means), col = "red", lwd = 2)

# Reset plotting parameters
par(mfrow = c(1, 1))
```
## 2. Sampling from Populations

Sampling is a fundamental process in statistics that involves selecting a subset of individuals, items, or observations from a larger population to estimate characteristics of that population. The method of sampling and the size of the sample play crucial roles in the validity and reliability of the conclusions drawn from statistical analysis.

### Types of Sampling Methods

- **Random Sampling**: Every member of the population has an equal change of being selected. This method minimizes selection bias and ensures that the sample is representative of the population.
- **Stratified Sampling**: The population is divided into distinct subgroups of strata (e.g., age, gender, income) and random samples are taken from each stratum. This ensures representation from all segments of the population.
- **Systematic Sampling**: A sample is selected using a fixed interval (e.g., every 10th individual from a list). This approach is useful when a complete list of the population is available and sorted.

### Sampling in the Context of the Central Limit Theorem

To demonstrate the Central Limit Theorem, we can take samples from different population distributions and calculate the sample means. As we draw larger samples, the distribution of the sample means should converge to a normal distribution, regardless of the shape of the distribution of the population.

## 3. Importance of Sample Size

```{r}
# set seed for reproducibility
set.seed(123)

# for this code example, we will reuse the exponential distribution

# calculate sample means for each sample size
small_sample_size <- sample_means(exponential_dist, 15, num_samples)
medium_sample_size <- sample_means(exponential_dist, 30, num_samples)
large_sample_size <- sample_means(exponential_dist, 60, num_samples)

# plotting histograms to visualize the distributions and sample means
par(mfrow = c(1, 4))  # set up a plotting grid of two rows and three columns

# plot exponential distribution
hist(exponential_dist, main = "Exponential Distribution", 
     xlab = "Value", col = "lightgreen", border = "white", freq = FALSE)
lines(density(exponential_dist), col = "green", lwd = 2)

# plot sample means for small sample size
hist(small_sample_size, main = "Sample Means (15)", 
     xlab = "Sample Mean", col = "lightgreen", border = "white", freq = FALSE)
lines(density(small_sample_size), col = "green", lwd = 2)

# plot sample means for medium sample size
hist(medium_sample_size, main = "Sample Means (30)", 
     xlab = "Sample Mean", col = "lightgreen", border = "white", freq = FALSE)
lines(density(medium_sample_size), col = "green", lwd = 2)

# plot sample means for large sample size
hist(large_sample_size, main = "Sample Means (60)", 
     xlab = "Sample Mean", col = "lightgreen", border = "white", freq = FALSE)
lines(density(large_sample_size), col = "green", lwd = 2)

# Reset plotting parameters
par(mfrow = c(1, 1))
```

## 4. Standard Error of the Mean

The Standard Error of the Mean is defined as the standard deviation of the sampling distribution of the sample means. It measures how much the sample mean is expected to fluctuate from the true population mean.

\[
\text{SEM} = \frac{\sigma}{\sqrt{n}}
\]

Where:

- \(\sigma\) is the standard deviation of the population.
- \(n\) is the sample size.


**In simple words**: The standard error of the mean, or simply standard error, indicates how different the population mean is likely to be from a sample mean. In statistics, data from samples is used to understand larger populations. Standard error matters because it helps you estimate how well your sample data represents the whole population.

### **Importance of the SEM**

- **Indicator of Precision**: The SEM provides a measure of how accurately a sample mean represents the population mean. A smaller SEM indicates a more precise estimate.
- **Informs Confidence Intervals**: The SEM is used to construct confidence intervals around the sample mean. As the sample size increases, the SEM decreases, leading to narrower confidence intervals.
- **Role in Hypothesis Testing**: The SEM is a critical component in hypothesis testing, allowing statisticians to assess whether observed differences between sample means are statistically significant.

## 5. Practical Applications of the CLT

### 1. **Quality Control**

- **Role of CLT**: In manufacturing, companies must ensure that their products meet specific quality standards. The CLT allows quality control engineers to take random samples from the production line and calculate the sample means of certain measurements (e.g., weight, dimensions). According to the CLT, as long as the sample size is sufficiently large, the distribution of these sample means will approximate a normal distribution, regardless of the shape of the population distribution. This means that quality control charts, which plot the means of samples over time, can be used to monitor consistency and identify any shifts in the manufacturing process. If sample means fall outside of predetermined control limits, it indicates that there may be a problem in production that requires investigation.

### 2. **Survey Research**

- **Role of CLT**: In political polling and survey research, the goal is to make inferences about a population based on a smaller sample. The CLT is vital here because it ensures that, as long as the sample size is large enough, the distribution of the sample means (e.g., the average support for a political candidate) will tend to follow a normal distribution. This normality allows pollsters to use statistical methods to estimate the population mean and construct confidence intervals. For instance, if a poll shows that 55% of sampled voters support a candidate with a standard error of 2%, the CLT allows researchers to state that they are 95% confident that the true support among the entire population lies between 51% and 59%. Thus, the CLT enables pollsters to communicate the reliability of their estimates.

### 3. **Clinical Trials**

- **Role of CLT**: In clinical trials, researchers evaluate the effectiveness of new treatments. They typically take samples of patients and measure outcomes (e.g., recovery times, symptom improvement). The CLT is crucial in this context because it allows researchers to assume that the distribution of sample means will be approximately normal as the sample size increases. This normal approximation is essential for hypothesis testing, which determines whether the treatment has a statistically significant effect compared to a control group. By applying the CLT, researchers can calculate p-values and confidence intervals for the treatment effect, guiding their conclusions about the treatment's efficacy. For example, if the average recovery time for the treatment group is significantly less than that of the control group, researchers can assert with statistical confidence that the treatment is effective.
